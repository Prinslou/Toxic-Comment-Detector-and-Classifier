{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.text import text_to_word_sequence\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Dense, Input, LSTM\n",
    "from keras.layers import Bidirectional, GlobalMaxPool1D\n",
    "from keras.layers import Embedding, Dropout\n",
    "from keras.models import Model\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import Sequential\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "data = pd.read_csv('train.csv').fillna(' ')\n",
    "data['comment_text'].fillna(\"missing\", inplace=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(data[\"comment_text\"],data[classes],test_size=0.15,random_state=76)\n",
    "data_text = pd.concat([X_train,X_test])\n",
    "print(type(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenization\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(list(data_text))\n",
    "X_traint = tokenizer.texts_to_sequences(X_train)\n",
    "X_testt = tokenizer.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#padding \n",
    "X_trainp = pad_sequences(X_traint, maxlen=250)\n",
    "X_testp = pad_sequences(X_testt, maxlen=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#glove embedding\n",
    "GLOVE_6B_50D_PATH = \"glove.6B.50d.txt\"\n",
    "index_len = len(tokenizer.word_index)\n",
    "glove = {}\n",
    "dimension = 50\n",
    "glove_matrix = np.zeros((index_len+1,dimension))\n",
    "glove_path = open(GLOVE_6B_50D_PATH)\n",
    "for line in tqdm(glove_path):\n",
    "    line_arr = line.split()\n",
    "    word = line_arr[0]\n",
    "    glove[word] = np.asarray(line_arr[1:], dtype='float32')\n",
    "glove_path.close()\n",
    "for word, idx in tqdm(tokenizer.word_index.items()):\n",
    "    if word in glove: glove_matrix[idx] = glove[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lstm model\n",
    "model_len = 250\n",
    "model = Sequential()\n",
    "model.add(Embedding(index_len + 1, dimension, weights = [glove_matrix], input_length = model_len, trainable = False))\n",
    "model.add(Bidirectional(LSTM(100, return_sequences = True)))\n",
    "model.add(GlobalMaxPool1D())\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.15))\n",
    "model.add(Dense(100, activation = \"relu\"))\n",
    "model.add(Dropout(0.15))\n",
    "model.add(Dense(70, activation = \"relu\"))\n",
    "model.add(Dropout(0.15))\n",
    "model.add(Dense(35, activation = \"relu\"))\n",
    "model.add(Dropout(0.15))\n",
    "model.add(Dense(6, activation = 'sigmoid'))\n",
    "model.summary()\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = optimizers.Adam(lr = 0.01), metrics = ['accuracy'])\n",
    "lstm = model.fit(X_trainp, y_train, epochs = 2, batch_size = 150, validation_split = 0.25)\n",
    "y_pred = model.predict(X_testp, verbose = 3, batch_size = 150) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
